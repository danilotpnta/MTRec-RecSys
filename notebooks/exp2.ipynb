{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from recsys.model import MultitaskRecommender\n",
    "from recsys.dataset import NewsDataModule\n",
    "\n",
    "if \"datamodule\" not in locals():\n",
    "    datamodule = NewsDataModule(\"../data\", batch_size=32)\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup()\n",
    "\n",
    "model = MultitaskRecommender(768, n_categories=datamodule.train_dataset.max_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 21)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>title</th><th>subtitle</th><th>last_modified_time</th><th>premium</th><th>body</th><th>published_time</th><th>image_ids</th><th>article_type</th><th>url</th><th>ner_clusters</th><th>entity_groups</th><th>topics</th><th>category</th><th>subcategory</th><th>category_str</th><th>total_inviews</th><th>total_pageviews</th><th>total_read_time</th><th>sentiment_score</th><th>sentiment_label</th></tr><tr><td>i32</td><td>str</td><td>str</td><td>datetime[μs]</td><td>bool</td><td>str</td><td>datetime[μs]</td><td>list[i64]</td><td>str</td><td>str</td><td>list[str]</td><td>list[str]</td><td>list[str]</td><td>i16</td><td>list[i16]</td><td>str</td><td>i32</td><td>i32</td><td>f32</td><td>f32</td><td>str</td></tr></thead><tbody><tr><td>3037230</td><td>&quot;Ishockey-spill…</td><td>&quot;ISHOCKEY: Isho…</td><td>2023-06-29 06:20:57</td><td>false</td><td>&quot;Ambitionerne o…</td><td>2003-08-28 08:55:00</td><td>null</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Mindre ulykke&quot;]</td><td>142</td><td>[327, 334]</td><td>&quot;sport&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9752</td><td>&quot;Negative&quot;</td></tr><tr><td>3044020</td><td>&quot;Prins Harry tv…</td><td>&quot;Hoffet tvang P…</td><td>2023-06-29 06:21:16</td><td>false</td><td>&quot;Den britiske t…</td><td>2005-06-29 08:47:00</td><td>[3097307, 3097197, 3104927]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[&quot;Harry&quot;, &quot;James Hewitt&quot;]</td><td>[&quot;PER&quot;, &quot;PER&quot;]</td><td>[&quot;Kriminalitet&quot;, &quot;Kendt&quot;, … &quot;Personfarlig kriminalitet&quot;]</td><td>414</td><td>[432]</td><td>&quot;underholdning&quot;</td><td>null</td><td>null</td><td>null</td><td>0.7084</td><td>&quot;Negative&quot;</td></tr><tr><td>3057622</td><td>&quot;Rådden kørsel …</td><td>&quot;Kan ikke straf…</td><td>2023-06-29 06:21:24</td><td>false</td><td>&quot;Slingrende spr…</td><td>2005-10-10 07:20:00</td><td>[3047102]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Transportmiddel&quot;, &quot;Bil&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9236</td><td>&quot;Negative&quot;</td></tr><tr><td>3073151</td><td>&quot;Mærsk-arvinger…</td><td>&quot;FANGET I FLODB…</td><td>2023-06-29 06:21:38</td><td>false</td><td>&quot;To oldebørn af…</td><td>2005-01-04 06:59:00</td><td>[3067474, 3067478, 3153705]</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Erhverv&quot;, &quot;Privat virksomhed&quot;, … &quot;Rejse&quot;]</td><td>118</td><td>[133]</td><td>&quot;nyheder&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9945</td><td>&quot;Negative&quot;</td></tr><tr><td>3193383</td><td>&quot;Skød svigersøn…</td><td>&quot;44-årig kvinde…</td><td>2023-06-29 06:22:57</td><td>false</td><td>&quot;En 44-årig mor…</td><td>2003-09-15 15:30:00</td><td>null</td><td>&quot;article_defaul…</td><td>&quot;https://ekstra…</td><td>[]</td><td>[]</td><td>[&quot;Kriminalitet&quot;, &quot;Personfarlig kriminalitet&quot;]</td><td>140</td><td>[]</td><td>&quot;krimi&quot;</td><td>null</td><td>null</td><td>null</td><td>0.9966</td><td>&quot;Negative&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 21)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ title     ┆ subtitle  ┆ last_modi ┆ … ┆ total_pag ┆ total_rea ┆ sentiment ┆ sentimen │\n",
       "│ d         ┆ ---       ┆ ---       ┆ fied_time ┆   ┆ eviews    ┆ d_time    ┆ _score    ┆ t_label  │\n",
       "│ ---       ┆ str       ┆ str       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---      │\n",
       "│ i32       ┆           ┆           ┆ datetime[ ┆   ┆ i32       ┆ f32       ┆ f32       ┆ str      │\n",
       "│           ┆           ┆           ┆ μs]       ┆   ┆           ┆           ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 3037230   ┆ Ishockey- ┆ ISHOCKEY: ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9752    ┆ Negative │\n",
       "│           ┆ spiller:  ┆ Ishockey- ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ Jeg       ┆ spilleren ┆ 06:20:57  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ troede    ┆ Seb…      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ jeg…      ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3044020   ┆ Prins     ┆ Hoffet    ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.7084    ┆ Negative │\n",
       "│           ┆ Harry     ┆ tvang     ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ tvunget   ┆ Prins     ┆ 06:21:16  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ til       ┆ Harry til ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ dna-test  ┆ at …      ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3057622   ┆ Rådden    ┆ Kan ikke  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9236    ┆ Negative │\n",
       "│           ┆ kørsel på ┆ straffes: ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ blå       ┆ Udenlands ┆ 06:21:24  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ plader    ┆ ke d…     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3073151   ┆ Mærsk-arv ┆ FANGET I  ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9945    ┆ Negative │\n",
       "│           ┆ inger i   ┆ FLODBØLGE ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ livsfare  ┆ N: Skibsr ┆ 06:21:38  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ edere…    ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 3193383   ┆ Skød      ┆ 44-årig   ┆ 2023-06-2 ┆ … ┆ null      ┆ null      ┆ 0.9966    ┆ Negative │\n",
       "│           ┆ svigersøn ┆ kvinde    ┆ 9         ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ gennem    ┆ tiltalt   ┆ 06:22:57  ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆ babydyne  ┆ for drab  ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│           ┆           ┆ …         ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "articles = pl.read_parquet(\"../data/demo/articles.parquet\")\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "You need to provide a path to the embeddings file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrecsys\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data, NewsDataset\n\u001b[1;32m      4\u001b[0m behaviors, history, articles \u001b[38;5;241m=\u001b[39m load_data(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/demo\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mNewsDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbehaviors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marticles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/project/MTRec-RecSys/src/recsys/dataset.py:102\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, behaviors, history, articles, history_size, max_labels, padding_value, max_length, embeddings_path, neg_count, test_mode)\u001b[0m\n\u001b[1;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[0;32m~/project/MTRec-RecSys/src/recsys/dataset.py:234\u001b[0m, in \u001b[0;36m_prepare_training_data\u001b[0;34m(self, embeddings_path)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prepare_training_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# Map article_id to index\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    217\u001b[0m         slice_join_dataframes(\n\u001b[1;32m    218\u001b[0m             df1\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbehaviors,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;241m.\u001b[39mwith_columns(pl\u001b[38;5;241m.\u001b[39mcol(DEFAULT_LABELS_COL)\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39mlen()\u001b[38;5;241m.\u001b[39malias(N_SAMPLES_COL))\n\u001b[1;32m    229\u001b[0m     )\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m    232\u001b[0m         pl\u001b[38;5;241m.\u001b[39mcol(DEFAULT_HISTORY_ARTICLE_ID_COL)\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39meval(\n\u001b[1;32m    233\u001b[0m             pl\u001b[38;5;241m.\u001b[39melement()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marticle_id_to_idx, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 234\u001b[0m         ),\n\u001b[1;32m    235\u001b[0m         pl\u001b[38;5;241m.\u001b[39mcol(DEFAULT_INVIEW_ARTICLES_COL)\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39meval(\n\u001b[1;32m    236\u001b[0m             pl\u001b[38;5;241m.\u001b[39melement()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marticle_id_to_idx, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    237\u001b[0m         ),\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m PolarsDataFrameWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mAssertionError\u001b[0m: You need to provide a path to the embeddings file."
     ]
    }
   ],
   "source": [
    "# %%prun\n",
    "from recsys.dataset import load_data, NewsDataset\n",
    "\n",
    "behaviors, history, articles = load_data(\"../data/demo\", \"validation\")\n",
    "embedding_path = \"/Users/Matey/project/MTRec-RecSys/data/xlm-roberta-base/FacebookAI_xlm_roberta_base/xlm_roberta_base.parquet\"\n",
    "dataset = NewsDataset(None, behaviors, history, articles, embeddings_path=embedding_path, test_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Matey/project/MTRec-RecSys/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/Matey/project/MTRec-RecSys/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from recsys.dataset import NewsDataModule\n",
    "\n",
    "datamodule = NewsDataModule(\"../data\", batch_size=32, dataset_type=\"v1\")\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(datamodule.train_dataset.behaviors[\"article_ids_clicked\"].list.len() >= 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1230179 function calls (1227854 primitive calls) in 3.882 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "    24724    1.910    0.000    3.152    0.000 dataset.py:257(__getitem__)\n",
      "     2319    0.308    0.000    0.308    0.000 {built-in method torch.stack}\n",
      "      774    0.206    0.000    3.815    0.005 dataloader.py:673(_next_data)\n",
      "    24724    0.202    0.000    0.202    0.000 {built-in method torch.tensor}\n",
      "    74172    0.163    0.000    0.163    0.000 {method 'to_list' of 'builtins.PySeries' objects}\n",
      "    24724    0.134    0.000    0.134    0.000 {method 'float' of 'torch._C.TensorBase' objects}\n",
      "    74172    0.109    0.000    0.433    0.000 frame.py:1582(__getitem__)\n",
      "    74172    0.097    0.000    0.097    0.000 {method 'get_column' of 'builtins.PyDataFrame' objects}\n",
      "      773    0.074    0.000    3.226    0.004 fetch.py:51(<listcomp>)\n",
      "    74172    0.070    0.000    0.289    0.000 frame.py:7021(get_column)\n",
      "    24724    0.068    0.000    0.068    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}\n",
      "    24724    0.066    0.000    0.066    0.000 {method 'slice' of 'builtins.PyDataFrame' objects}\n",
      "    74172    0.064    0.000    0.123    0.000 _wrap.py:20(wrap_s)\n",
      "    24724    0.051    0.000    0.201    0.000 classes.py:10(__getitem__)\n",
      "   255754    0.042    0.000    0.047    0.000 {built-in method builtins.isinstance}\n",
      "    74172    0.041    0.000    0.060    0.000 series.py:361(_from_pyseries)\n",
      "    74172    0.040    0.000    0.203    0.000 series.py:4145(to_list)\n",
      "    24724    0.031    0.000    0.118    0.000 frame.py:4898(slice)\n",
      "    98896    0.026    0.000    0.026    0.000 {built-in method __new__ of type object at 0x1010f0d98}\n",
      "        1    0.021    0.021    3.882    3.882 <string>:1(<module>)\n",
      " 3092/773    0.017    0.000    0.362    0.000 collate.py:88(collate)\n",
      "    24724    0.015    0.000    0.022    0.000 frame.py:427(_from_pydf)\n",
      "    24729    0.015    0.000    0.027    0.000 frame.py:1157(height)\n",
      "      774    0.013    0.000    0.013    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "    24729    0.012    0.000    0.012    0.000 {method 'height' of 'builtins.PyDataFrame' objects}\n",
      "     2319    0.009    0.000    0.318    0.000 collate.py:155(collate_tensor_fn)\n",
      "    24724    0.009    0.000    0.012    0.000 collate.py:139(<genexpr>)\n",
      "      774    0.009    0.000    0.015    0.000 sampler.py:274(__iter__)\n",
      "      774    0.009    0.000    3.860    0.005 dataloader.py:626(__next__)\n",
      "      774    0.007    0.000    0.007    0.000 {built-in method torch._ops.profiler.}\n",
      "      774    0.007    0.000    0.016    0.000 profiler.py:610(__exit__)\n",
      "    24725    0.005    0.000    0.006    0.000 sampler.py:152(__iter__)\n",
      "      773    0.004    0.000    0.016    0.000 {built-in method builtins.all}\n",
      "      774    0.003    0.000    0.005    0.000 profiler.py:593(__init__)\n",
      "      773    0.003    0.000    0.324    0.000 collate.py:144(<listcomp>)\n",
      "24735/24730    0.003    0.000    0.003    0.000 {built-in method builtins.len}\n",
      "      773    0.003    0.000    3.592    0.005 fetch.py:46(fetch)\n",
      "     1552    0.002    0.000    0.004    0.000 {built-in method _abc._abc_instancecheck}\n",
      "      774    0.002    0.000    0.016    0.000 profiler.py:604(__enter__)\n",
      "      773    0.002    0.000    0.364    0.000 collate.py:216(default_collate)\n",
      "      774    0.001    0.000    0.001    0.000 typing.py:359(inner)\n",
      "      774    0.001    0.000    0.008    0.000 _ops.py:512(__call__)\n",
      "      773    0.001    0.000    0.002    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "        2    0.001    0.001    0.001    0.001 {method 'tolist' of 'torch._C.TensorBase' objects}\n",
      "     1552    0.001    0.000    0.005    0.000 <frozen abc>:117(__instancecheck__)\n",
      "      774    0.001    0.000    0.014    0.000 _ops.py:750(__call__)\n",
      "     1547    0.001    0.000    0.016    0.000 {built-in method builtins.next}\n",
      "        2    0.001    0.000    0.001    0.000 {built-in method torch.randperm}\n",
      "     1549    0.001    0.000    0.001    0.000 {built-in method builtins.hasattr}\n",
      "      773    0.001    0.000    0.001    0.000 <frozen _collections_abc>:315(__subclasshook__)\n",
      "     2319    0.001    0.000    0.001    0.000 worker.py:89(get_worker_info)\n",
      "      774    0.001    0.000    0.017    0.000 dataloader.py:620(_next_index)\n",
      "      773    0.000    0.000    0.002    0.000 <frozen abc>:121(__subclasscheck__)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "      774    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "      774    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "        1    0.000    0.000    3.882    3.882 {built-in method builtins.exec}\n",
      "      774    0.000    0.000    0.000    0.000 _jit_internal.py:1120(is_scripting)\n",
      "      774    0.000    0.000    0.000    0.000 __init__.py:126(annotate)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:226(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method torch.empty}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:565(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 dataset.py:721(train_dataloader)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:132(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap>:1207(_handle_fromlist)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C.TensorBase' objects}\n",
      "    20/19    0.000    0.000    0.000    0.000 dataloader.py:417(__setattr__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:393(multiprocessing_context)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.set_vital}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:659(__init__)\n",
      "        5    0.000    0.000    0.000    0.000 dataset.py:254(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "        4    0.000    0.000    0.000    0.000 sampler.py:145(num_samples)\n",
      "        5    0.000    0.000    0.000    0.000 frame.py:1816(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:74(create_fetcher)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:93(_get_distributed_settings)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:948(is_initialized)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:382(_get_iterator)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:583(WORLD)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:261(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 fetch.py:8(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:426(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:128(is_available)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:9(is_available)\n",
      "        3    0.000    0.000    0.000    0.000 dataloader.py:441(_auto_collation)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:486(check_worker_number_rationality)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:453(default_pg)\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:119(_is_compiled)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:445(_index_sampler)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}"
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# loader = DataLoader(datamodule.train_dataset, batch_size=512, shuffle=True, collate_fn=None)\n",
    "loader = datamodule.train_dataloader()\n",
    "\n",
    "for batch in loader:\n",
    "    hist, cand, labes = batch\n",
    "    # print(hist.shape, cand.shape, labes.shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'behaviors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m dataset\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     slice_join_dataframes(\n\u001b[0;32m----> 3\u001b[0m         df1\u001b[38;5;241m=\u001b[39m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbehaviors\u001b[49m,\n\u001b[1;32m      4\u001b[0m         df2\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[1;32m      5\u001b[0m         on\u001b[38;5;241m=\u001b[39mDEFAULT_USER_COL,\n\u001b[1;32m      6\u001b[0m         how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     )\u001b[38;5;241m.\u001b[39mselect(COLUMNS)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m.\u001b[39mwith_columns(pl\u001b[38;5;241m.\u001b[39mcol(DEFAULT_INVIEW_ARTICLES_COL)\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39meval(pl\u001b[38;5;241m.\u001b[39melement()\u001b[38;5;241m.\u001b[39meq(DEFAULT_CLICKED_ARTICLES_COL))\u001b[38;5;241m.\u001b[39mcast(pl\u001b[38;5;241m.\u001b[39mUInt8))\u001b[38;5;241m.\u001b[39malias(DEFAULT_LABELS_COL)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;241m.\u001b[39mwith_columns(pl\u001b[38;5;241m.\u001b[39mcol(DEFAULT_LABELS_COL)\u001b[38;5;241m.\u001b[39mlist\u001b[38;5;241m.\u001b[39mlen()\u001b[38;5;241m.\u001b[39malias(N_SAMPLES_COL))\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'behaviors'"
     ]
    }
   ],
   "source": [
    "dataset.data = (\n",
    "    slice_join_dataframes(\n",
    "        df1=dataset.behaviors,\n",
    "        df2=dataset.history,\n",
    "        on=DEFAULT_USER_COL,\n",
    "        how=\"left\",\n",
    "    ).select(COLUMNS)\n",
    "    .with_columns(pl.col(DEFAULT_INVIEW_ARTICLES_COL).list.eval(pl.element().eq(DEFAULT_CLICKED_ARTICLES_COL)).cast(pl.UInt8)).alias(DEFAULT_LABELS_COL)\n",
    "    .with_columns(pl.col(DEFAULT_LABELS_COL).list.len().alias(N_SAMPLES_COL))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7424)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.predictions[0]\n",
    "labels = model.labels[0]\n",
    "from torch.nn import functional as F\n",
    "\n",
    "F.binary_cross_entropy_with_logits(model.predictions[0], model.labels[0].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([5, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected floating point type for target with class probabilities, got Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# (batch_size, candidates)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# (batch_size, candidates)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "File \u001b[0;32m~/project/MTRec-RecSys/.venv/lib/python3.11/site-packages/torch/nn/functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected floating point type for target with class probabilities, got Long"
     ]
    }
   ],
   "source": [
    "print(scores.shape) # (batch_size, candidates)\n",
    "print(labels.shape) # (batch_size, candidates)\n",
    "\n",
    "# loss = F.cross_entropy(scores, labels)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 1],\n",
       "        [0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.labels[0].T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
