{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTRec:\n",
    "\n",
    "Given $I$ number historical clicked news of a user $ N^h = [n_1^h , n_2^h, ..., n^h_I ]$ and a set of $J$ candidate news $ N^c = [n^c_1, n^c_2, ..., n^c_J ] $, our goal is to calculate the user interest score $s_j$ of each candidate news according to the historical behavior of the user, then the candidate news with the highest interest score is recommended to the user. \n",
    "\n",
    "For each news, we have its title text T , category label $p^c$, and entity set E. \n",
    "\n",
    "## 2.1 News Recommendation Framework\n",
    "\n",
    "As shown in Figure 2, there are three main components in news recommendation framework, i.e., a news encoder, a user encoder, and a click predictor. \n",
    "### News Encoder\n",
    "For each news n, we encode its title with pre-trained BRET (Devlin et al., 2019). Specifically, we feed the tokenized text T into the BERT model and **adopt the embedding of [CLS] token as the news representation r**. \n",
    "\n",
    "We denote the encoded vectors of historical clicked news $N^h$ and candidate news $N^c$ as $R^h = [r^h_1 , r^h_2 , ..., r^h_I ]$ and $R^c = [r^c_1, r^c_2, ..., r^c_J ]$, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 17:31:34.511322: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/Matey/project/MTRec-RecSys/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation & Maths imports\n",
    "import os.path\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "from pprint import pprint\n",
    "\n",
    "# Torch & Transformer imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoModel, \n",
    "    AutoTokenizer, \n",
    "    RobertaModel, \n",
    "    RobertaTokenizer, \n",
    "    XLMRobertaModel, \n",
    "    XLMRobertaTokenizer\n",
    ")\n",
    "\n",
    "# ebrec constants\n",
    "from ebrec.utils._constants import (\n",
    "    DEFAULT_ARTICLE_ID_COL,         # article_id\n",
    "    DEFAULT_TITLE_COL,              # title\n",
    "    DEFAULT_BODY_COL,               # body\n",
    "    DEFAULT_SUBTITLE_COL,           # subtitle\n",
    "    DEFAULT_TOPICS_COL,             # topics\n",
    "    DEFAULT_CATEGORY_STR_COL,       # category_str\n",
    "    DEFAULT_LABELS_COL,             # labels\n",
    "    DEFAULT_USER_COL,               # user_id\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL, # article_id_fixed\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,    # article_ids_inview\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,   # article_ids_clicked\n",
    "    DEFAULT_IMPRESSION_ID_COL       # impression_id\n",
    ")\n",
    "\n",
    "# ebrec utils\n",
    "from ebrec.utils._articles_behaviors import map_list_article_id_to_value\n",
    "from ebrec.utils._behaviors import truncate_history, create_binary_labels_column\n",
    "from ebrec.utils._polars import slice_join_dataframes\n",
    "from ebrec.utils._python import (\n",
    "    generate_unique_name,\n",
    "    repeat_by_list_values_from_matrix,\n",
    "    create_lookup_objects,\n",
    "    create_lookup_dict,\n",
    ")\n",
    "\n",
    "# Columns to be used in the dataset processing\n",
    "COLUMNS = [\n",
    "    DEFAULT_USER_COL,                # \"user_id\"\n",
    "    DEFAULT_HISTORY_ARTICLE_ID_COL,  # \"article_id_fixed\"\n",
    "    DEFAULT_INVIEW_ARTICLES_COL,     # \"article_ids_inview\"\n",
    "    DEFAULT_CLICKED_ARTICLES_COL,    # \"article_ids_clicked\"\n",
    "    DEFAULT_IMPRESSION_ID_COL,       # \"impression_id\"\n",
    "]\n",
    "DEFAULT_TOKENS_COL = \"tokens\"\n",
    "N_SAMPLES_COL = \"n_samples\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Embeddings Shape: (125541, 2)\n",
      "Sample Embedding: shape: (5, 2)\n",
      "┌────────────┬───────────────────────────────────┐\n",
      "│ article_id ┆ FacebookAI/xlm-roberta-base       │\n",
      "│ ---        ┆ ---                               │\n",
      "│ i32        ┆ list[f32]                         │\n",
      "╞════════════╪═══════════════════════════════════╡\n",
      "│ 3000022    ┆ [0.102449, 0.101148, … -0.020715… │\n",
      "│ 3000063    ┆ [0.107297, 0.103073, … 0.004873]  │\n",
      "│ 3000613    ┆ [0.125139, 0.124621, … -0.05177]  │\n",
      "│ 3000700    ┆ [0.105697, 0.076335, … -0.034872… │\n",
      "│ 3000840    ┆ [0.098175, 0.114629, … -0.024436… │\n",
      "└────────────┴───────────────────────────────────┘\n",
      "Joined Articles with Embeddings: (11777, 7)\n",
      "Sample Article Embedding: shape: (5, 7)\n",
      "┌────────────┬──────────────┬──────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
      "│ article_id ┆ title        ┆ body         ┆ subtitle    ┆ topics      ┆ category_st ┆ tokens      │\n",
      "│ ---        ┆ ---          ┆ ---          ┆ ---         ┆ ---         ┆ r           ┆ ---         │\n",
      "│ i32        ┆ str          ┆ str          ┆ str         ┆ list[str]   ┆ ---         ┆ list[f32]   │\n",
      "│            ┆              ┆              ┆             ┆             ┆ str         ┆             │\n",
      "╞════════════╪══════════════╪══════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
      "│ 3037230    ┆ Ishockey-spi ┆ Ambitionerne ┆ ISHOCKEY:   ┆ [\"Kriminali ┆ sport       ┆ [0.111132,  │\n",
      "│            ┆ ller: Jeg    ┆ om at komme  ┆ Ishockey-sp ┆ tet\",       ┆             ┆ 0.119653, … │\n",
      "│            ┆ troede jeg…  ┆ til USA…     ┆ illeren     ┆ \"Kendt\", …  ┆             ┆ -0.008356…  │\n",
      "│            ┆              ┆              ┆ Seb…        ┆ \"Min…       ┆             ┆             │\n",
      "│ 3044020    ┆ Prins Harry  ┆ Den britiske ┆ Hoffet      ┆ [\"Kriminali ┆ underholdni ┆ [0.113472,  │\n",
      "│            ┆ tvunget til  ┆ tabloidavis  ┆ tvang Prins ┆ tet\",       ┆ ng          ┆ 0.097556, … │\n",
      "│            ┆ dna-test     ┆ The Sun…     ┆ Harry til   ┆ \"Kendt\", …  ┆             ┆ -0.016068…  │\n",
      "│            ┆              ┆              ┆ at …        ┆ \"Per…       ┆             ┆             │\n",
      "│ 3057622    ┆ Rådden       ┆ Slingrende   ┆ Kan ikke    ┆ [\"Kriminali ┆ nyheder     ┆ [0.090726,  │\n",
      "│            ┆ kørsel på    ┆ spritkørsel. ┆ straffes:   ┆ tet\", \"Tran ┆             ┆ 0.125526, … │\n",
      "│            ┆ blå plader   ┆ Grove ov…    ┆ Udenlandske ┆ sportmidde… ┆             ┆ -0.011349…  │\n",
      "│            ┆              ┆              ┆ d…          ┆             ┆             ┆             │\n",
      "│ 3073151    ┆ Mærsk-arving ┆ To oldebørn  ┆ FANGET I    ┆ [\"Erhverv\", ┆ nyheder     ┆ [0.129573,  │\n",
      "│            ┆ er i         ┆ af           ┆ FLODBØLGEN: ┆ \"Privat vir ┆             ┆ 0.132865, … │\n",
      "│            ┆ livsfare     ┆ skibsreder   ┆ Skibsredere ┆ ksomhed\",…  ┆             ┆ -0.009751…  │\n",
      "│            ┆              ┆ Mærsk …      ┆ …           ┆             ┆             ┆             │\n",
      "│ 3193383    ┆ Skød         ┆ En 44-årig   ┆ 44-årig     ┆ [\"Kriminali ┆ krimi       ┆ [0.108794,  │\n",
      "│            ┆ svigersøn    ┆ mormor blev  ┆ kvinde      ┆ tet\", \"Pers ┆             ┆ 0.100466, … │\n",
      "│            ┆ gennem       ┆ i dag fre…   ┆ tiltalt for ┆ onfarlig k… ┆             ┆ 0.000001]   │\n",
      "│            ┆ babydyne     ┆              ┆ drab …      ┆             ┆             ┆             │\n",
      "└────────────┴──────────────┴──────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "class NewsDataset(Dataset):\n",
    "\n",
    "    behaviors: pl.DataFrame\n",
    "    history: pl.DataFrame\n",
    "    articles: pl.DataFrame\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer,\n",
    "        behaviors: pl.DataFrame,\n",
    "        history: pl.DataFrame,\n",
    "        articles: pl.DataFrame,\n",
    "        history_size: int = 30,\n",
    "        padding_value: int = 0,\n",
    "        max_length=128,\n",
    "        batch_size=32,\n",
    "        embeddings_path=None,\n",
    "    ):\n",
    "        self.behaviors = behaviors\n",
    "        self.history = history\n",
    "        self.articles = articles\n",
    "        self.history_size = history_size\n",
    "        self.padding_value = padding_value\n",
    "        self.batch_size = batch_size\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "        # TODO: I decided to instead only use pre-computed embeddings for now. You might want to look into this later down the line and implement custom embeddings (and e.g. train BERT as well).\n",
    "        self.embeddings_path = embeddings_path\n",
    "\n",
    "        # NOTE: Keep an eye on this if memory issues arise\n",
    "        self.articles = self.articles.select(\n",
    "            [\n",
    "                DEFAULT_ARTICLE_ID_COL,     # article_id\n",
    "                DEFAULT_TITLE_COL,          # title\n",
    "                DEFAULT_BODY_COL,           # body\n",
    "                DEFAULT_SUBTITLE_COL,       # subtitle\n",
    "                DEFAULT_TOPICS_COL,         # topics\n",
    "                DEFAULT_CATEGORY_STR_COL,   # category_str\n",
    "            ]\n",
    "        ).collect()\n",
    "\n",
    "        self._process_history()\n",
    "        self._prepare_training_data()\n",
    "\n",
    "    def _process_history(self):\n",
    "        self.history = (\n",
    "            self.history.select(\n",
    "                [\n",
    "                    DEFAULT_USER_COL,               # \"user_id\"\n",
    "                    DEFAULT_HISTORY_ARTICLE_ID_COL  # article_id_fixed\n",
    "                ]\n",
    "            )\n",
    "            .pipe(\n",
    "                truncate_history,\n",
    "                column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "                history_size=self.history_size,\n",
    "                padding_value=self.padding_value,\n",
    "                enable_warning=False,\n",
    "            )\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "    def _prepare_training_data(self):\n",
    "        self.behaviors = self.behaviors.collect()\n",
    "\n",
    "        self.data: pl.DataFrame = (\n",
    "            slice_join_dataframes(\n",
    "                df1=self.behaviors,\n",
    "                df2=self.history,\n",
    "                on=DEFAULT_USER_COL,\n",
    "                how=\"left\",\n",
    "            )\n",
    "            .select(COLUMNS)\n",
    "            .pipe(create_binary_labels_column, seed=42, label_col=DEFAULT_LABELS_COL)\n",
    "            .with_columns(\n",
    "                pl.col(DEFAULT_LABELS_COL).list.len().alias(N_SAMPLES_COL)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        assert self.embeddings_path is not None, \"You need to provide a path to the embeddings file.\"\n",
    "        embeddings = pl.read_parquet(self.embeddings_path)\n",
    "        print(\"Loaded Embeddings Shape:\", embeddings.shape)\n",
    "        print(\"Sample Embedding:\", embeddings.head())\n",
    "\n",
    "        self.articles = (\n",
    "            self.articles.lazy()\n",
    "            .join(embeddings.lazy(), on=DEFAULT_ARTICLE_ID_COL, how=\"inner\")\n",
    "            .rename({\"FacebookAI/xlm-roberta-base\": DEFAULT_TOKENS_COL})\n",
    "            .collect()\n",
    "        )\n",
    "\n",
    "        print(\"Joined Articles with Embeddings:\", self.articles.shape)\n",
    "        print(\"Sample Article Embedding:\", self.articles.head())\n",
    "\n",
    "        article_dict = create_lookup_dict(\n",
    "            self.articles.select(DEFAULT_ARTICLE_ID_COL, DEFAULT_TOKENS_COL),\n",
    "            key=DEFAULT_ARTICLE_ID_COL,\n",
    "            value=DEFAULT_TOKENS_COL,\n",
    "        )\n",
    "\n",
    "        self.lookup_indexes, self.lookup_matrix = create_lookup_objects(\n",
    "            article_dict, unknown_representation=\"zeros\"\n",
    "        )\n",
    "\n",
    "        # print(\"Embeddings Shape:\", self.lookup_matrix.shape)\n",
    "        # print(\"Sample Embedding:\", self.lookup_matrix[0])\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of batch steps in the data\n",
    "        \"\"\"\n",
    "        return int(ceil(self.behaviors.shape[0] / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Get the batch of samples for the given index.\n",
    "\n",
    "        Note: The dataset class provides a single index for each iteration. The batching is done internally in this method\n",
    "        to utilize and optimize for speed. This can be seen as a mini-batching approach.\n",
    "\n",
    "        Args:\n",
    "            index (int): An integer index.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor]: A tuple containing the input features and labels as torch Tensors.\n",
    "                Note, the output of the PyTorch DataLoader is (1, *shape), where 1 is the DataLoader's batch_size.\n",
    "        \"\"\"\n",
    "        # Clever way to batch the data:\n",
    "        batch_indices = range(index * self.batch_size,\n",
    "                              (index + 1) * self.batch_size)\n",
    "        batch = self.data[batch_indices]\n",
    "\n",
    "        x = (\n",
    "            batch.drop(DEFAULT_LABELS_COL)\n",
    "            .pipe(\n",
    "                map_list_article_id_to_value,\n",
    "                behaviors_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "                mapping=self.lookup_indexes,\n",
    "                fill_nulls=[0],\n",
    "            )\n",
    "            .pipe(\n",
    "                map_list_article_id_to_value,\n",
    "                behaviors_column=DEFAULT_INVIEW_ARTICLES_COL,\n",
    "                mapping=self.lookup_indexes,\n",
    "                fill_nulls=[0],\n",
    "            )\n",
    "        )\n",
    "        # =>\n",
    "        repeats = np.array(batch[N_SAMPLES_COL])\n",
    "        # =>\n",
    "        history_input = repeat_by_list_values_from_matrix(\n",
    "            input_array=x[DEFAULT_HISTORY_ARTICLE_ID_COL].to_list(),\n",
    "            matrix=self.lookup_matrix,\n",
    "            repeats=repeats,\n",
    "        ).squeeze(2)\n",
    "        # =>\n",
    "        candidate_input = self.lookup_matrix[\n",
    "            x[DEFAULT_INVIEW_ARTICLES_COL].explode().to_list()\n",
    "        ]\n",
    "        # =>\n",
    "        history_input = torch.tensor(history_input)\n",
    "        candidate_input = torch.tensor(candidate_input)\n",
    "        y = torch.tensor(batch[DEFAULT_LABELS_COL].explode(), dtype=torch.float32).view(\n",
    "            -1, 1\n",
    "        )\n",
    "        # ========================\n",
    "        return history_input, candidate_input, y\n",
    "\n",
    "\n",
    "def load_data(tokenizer, data_path, split=\"train\", embeddings_path=None):\n",
    "    _data_path = os.path.join(data_path, split)\n",
    "\n",
    "    df_behaviors = pl.scan_parquet(_data_path + \"/behaviors.parquet\")\n",
    "    df_history = pl.scan_parquet(_data_path + \"/history.parquet\")\n",
    "    df_articles = pl.scan_parquet(data_path + \"/articles.parquet\")\n",
    "\n",
    "    return NewsDataset(tokenizer, df_behaviors, df_history, df_articles, embeddings_path=embeddings_path)\n",
    "\n",
    "\n",
    "# Model and tokenizer initialization\n",
    "MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "\n",
    "# NOTE: We need the multilingual model for the dataset\n",
    "# bert = XLMRobertaModel.from_pretrained(MODEL_NAME)\n",
    "# tokenizer = XLMRobertaTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "DATA_PATH = \"../data/demo\"\n",
    "EMBEDDINGS_PATH = \"../data/FacebookAI-xlm-roberta-base/FacebookAI_xlm_roberta_base/xlm_roberta_base.parquet\"\n",
    "\n",
    "tokenizer = None\n",
    "dataset = load_data(tokenizer, DATA_PATH, split=\"train\",\n",
    "                    embeddings_path=EMBEDDINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDatasetV2(NewsDataset):\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    def __getitem__(self, index: int):\n",
    "        sample = dataset.data[index]\n",
    "        sample = sample.pipe(\n",
    "            map_list_article_id_to_value,\n",
    "            behaviors_column=DEFAULT_HISTORY_ARTICLE_ID_COL,\n",
    "            mapping=dataset.lookup_indexes,\n",
    "            fill_nulls=[0],\n",
    "\n",
    "        ).pipe(\n",
    "            map_list_article_id_to_value,\n",
    "            behaviors_column=DEFAULT_INVIEW_ARTICLES_COL,\n",
    "            mapping=dataset.lookup_indexes,\n",
    "            fill_nulls=[0],\n",
    "        )\n",
    "\n",
    "        _history = sample[DEFAULT_HISTORY_ARTICLE_ID_COL].explode().explode().to_list()\n",
    "        history = torch.from_numpy(dataset.lookup_matrix[_history])\n",
    "        _candidates = sample[DEFAULT_INVIEW_ARTICLES_COL].explode().explode().to_list()\n",
    "        candidates = torch.from_numpy(dataset.lookup_matrix[_candidates])\n",
    "        # dataset.lookup_indexes\n",
    "        labels = torch.tensor(sample[DEFAULT_LABELS_COL].to_list()[0])\n",
    "        return history, candidates, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Embeddings Shape: (125541, 2)\n",
      "Sample Embedding: shape: (5, 2)\n",
      "┌────────────┬───────────────────────────────────┐\n",
      "│ article_id ┆ FacebookAI/xlm-roberta-base       │\n",
      "│ ---        ┆ ---                               │\n",
      "│ i32        ┆ list[f32]                         │\n",
      "╞════════════╪═══════════════════════════════════╡\n",
      "│ 3000022    ┆ [0.102449, 0.101148, … -0.020715… │\n",
      "│ 3000063    ┆ [0.107297, 0.103073, … 0.004873]  │\n",
      "│ 3000613    ┆ [0.125139, 0.124621, … -0.05177]  │\n",
      "│ 3000700    ┆ [0.105697, 0.076335, … -0.034872… │\n",
      "│ 3000840    ┆ [0.098175, 0.114629, … -0.024436… │\n",
      "└────────────┴───────────────────────────────────┘\n",
      "Joined Articles with Embeddings: (11777, 7)\n",
      "Sample Article Embedding: shape: (5, 7)\n",
      "┌────────────┬──────────────┬──────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
      "│ article_id ┆ title        ┆ body         ┆ subtitle    ┆ topics      ┆ category_st ┆ tokens      │\n",
      "│ ---        ┆ ---          ┆ ---          ┆ ---         ┆ ---         ┆ r           ┆ ---         │\n",
      "│ i32        ┆ str          ┆ str          ┆ str         ┆ list[str]   ┆ ---         ┆ list[f32]   │\n",
      "│            ┆              ┆              ┆             ┆             ┆ str         ┆             │\n",
      "╞════════════╪══════════════╪══════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
      "│ 3037230    ┆ Ishockey-spi ┆ Ambitionerne ┆ ISHOCKEY:   ┆ [\"Kriminali ┆ sport       ┆ [0.111132,  │\n",
      "│            ┆ ller: Jeg    ┆ om at komme  ┆ Ishockey-sp ┆ tet\",       ┆             ┆ 0.119653, … │\n",
      "│            ┆ troede jeg…  ┆ til USA…     ┆ illeren     ┆ \"Kendt\", …  ┆             ┆ -0.008356…  │\n",
      "│            ┆              ┆              ┆ Seb…        ┆ \"Min…       ┆             ┆             │\n",
      "│ 3044020    ┆ Prins Harry  ┆ Den britiske ┆ Hoffet      ┆ [\"Kriminali ┆ underholdni ┆ [0.113472,  │\n",
      "│            ┆ tvunget til  ┆ tabloidavis  ┆ tvang Prins ┆ tet\",       ┆ ng          ┆ 0.097556, … │\n",
      "│            ┆ dna-test     ┆ The Sun…     ┆ Harry til   ┆ \"Kendt\", …  ┆             ┆ -0.016068…  │\n",
      "│            ┆              ┆              ┆ at …        ┆ \"Per…       ┆             ┆             │\n",
      "│ 3057622    ┆ Rådden       ┆ Slingrende   ┆ Kan ikke    ┆ [\"Kriminali ┆ nyheder     ┆ [0.090726,  │\n",
      "│            ┆ kørsel på    ┆ spritkørsel. ┆ straffes:   ┆ tet\", \"Tran ┆             ┆ 0.125526, … │\n",
      "│            ┆ blå plader   ┆ Grove ov…    ┆ Udenlandske ┆ sportmidde… ┆             ┆ -0.011349…  │\n",
      "│            ┆              ┆              ┆ d…          ┆             ┆             ┆             │\n",
      "│ 3073151    ┆ Mærsk-arving ┆ To oldebørn  ┆ FANGET I    ┆ [\"Erhverv\", ┆ nyheder     ┆ [0.129573,  │\n",
      "│            ┆ er i         ┆ af           ┆ FLODBØLGEN: ┆ \"Privat vir ┆             ┆ 0.132865, … │\n",
      "│            ┆ livsfare     ┆ skibsreder   ┆ Skibsredere ┆ ksomhed\",…  ┆             ┆ -0.009751…  │\n",
      "│            ┆              ┆ Mærsk …      ┆ …           ┆             ┆             ┆             │\n",
      "│ 3193383    ┆ Skød         ┆ En 44-årig   ┆ 44-årig     ┆ [\"Kriminali ┆ krimi       ┆ [0.108794,  │\n",
      "│            ┆ svigersøn    ┆ mormor blev  ┆ kvinde      ┆ tet\", \"Pers ┆             ┆ 0.100466, … │\n",
      "│            ┆ gennem       ┆ i dag fre…   ┆ tiltalt for ┆ onfarlig k… ┆             ┆ 0.000001]   │\n",
      "│            ┆ babydyne     ┆              ┆ drab …      ┆             ┆             ┆             │\n",
      "└────────────┴──────────────┴──────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 768\n",
    "W = nn.Linear(hidden_dim, hidden_dim)\n",
    "q = nn.Parameter(torch.randn(hidden_dim))\n",
    "dataset = NewsDatasetV2(tokenizer, dataset.behaviors.lazy(), dataset.history.lazy(), dataset.articles.lazy(), embeddings_path=EMBEDDINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 768]) torch.Size([11, 768]) torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "history, candidates, labels = dataset[0]\n",
    "print(history.shape, candidates.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = q * F.tanh(W(history))\n",
    "att_weight = F.softmax(att, dim=-1)\n",
    "\n",
    "user_embedding = torch.sum(history * att_weight, dim=0)\n",
    "\n",
    "# print(f\"{user_embedding.shape=}\")\n",
    "# print(f\"{user_embedding.unsqueeze(-1).shape=}\")\n",
    "# score = torch.bmm(candidates, user_embedding.unsqueeze(-1)) # B x M x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.9078, 10.8969, 10.8815, 10.8896, 10.8903, 10.8746, 10.9196, 10.8738,\n",
       "        10.8796, 10.8819, 10.8866], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.bmm(candidates.unsqueeze(0), user_embedding.unsqueeze(-1).unsqueeze(0)).squeeze()\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_nll_loss(preds, labels):\n",
    "    pos = preds[labels == 1].exp()\n",
    "    neg = preds[labels == 0].exp().sum(-1)\n",
    "    return - torch.log(pos / (pos + neg)).mean()\n",
    "\n",
    "# positive_nll_loss(scores.squeeze(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24724 [00:00<?, ?it/s, loss=2.41]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 675/24724 [00:14<08:28, 47.32it/s, loss=1.94]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jh/2h78bdyj1qzfbls2j1yfbv9c0000gn/T/ipykernel_22362/364244854.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0matt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0matt_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/MTRec-RecSys/.venv/lib/python3.11/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m                         \u001b[0mlast_print_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_print_n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m                         \u001b[0mlast_print_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_print_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jh/2h78bdyj1qzfbls2j1yfbv9c0000gn/T/ipykernel_22362/3890473861.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0m_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDEFAULT_HISTORY_ARTICLE_ID_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_history\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0m_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDEFAULT_INVIEW_ARTICLES_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_candidates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# dataset.lookup_indexes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDEFAULT_LABELS_COL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/project/MTRec-RecSys/.venv/lib/python3.11/site-packages/polars/series/utils.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mnamespace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_accessor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnamespace\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/project/MTRec-RecSys/.venv/lib/python3.11/site-packages/polars/expr/expr.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m-> 4444\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4445\u001b[0m         \"\"\"\n\u001b[1;32m   4446\u001b[0m         \u001b[0mExplode\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mexpression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam([q, W.weight, W.bias], lr=0.0005)\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    losses = []\n",
    "    q.requires = True\n",
    "    W.training = True\n",
    "    with tqdm(dataset) as pbar:\n",
    "        for batch in pbar:\n",
    "            history, candidates, labels = batch\n",
    "            att = q * F.tanh(W(history))\n",
    "            att_weight = F.softmax(att, dim=-1)\n",
    "            user_embedding = torch.sum(history * att_weight, dim=0)\n",
    "            scores = torch.bmm(candidates.unsqueeze(0), user_embedding.unsqueeze(-1).unsqueeze(0)).squeeze()\n",
    "            loss = positive_nll_loss(scores.squeeze(), labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            pbar.set_postfix(loss=losses[-1])\n",
    "    print(f\"Average Loss: {np.mean(losses)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        self.bert = bert\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        outputs = self.bert(input_ids)\n",
    "        outputs = outputs.last_hidden_state[:, 0, :]\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Encoder\n",
    "To gain a user representation from the representations of historical clicked news, existing methods usually employ sequential (An et al., 2019) or attentive models (Wu et al., 2019d; Li et al., 2018). In this paper, we adopt additive attention as the user encoder to compress the historical information Rh. The user representation $r^u$ is then denoted as: \n",
    "\n",
    "$$ \\textbf{r}^u = \\sum_{i=1}^I \\textbf{a}^u_i \\textbf{r}^h_i , \\textbf{a}^u_i = \\text{softmax}(\\textbf{q}^u·\\tanh(W^u r^h_i )),$$\n",
    "\n",
    " where qu and Wu are trainable parameters. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MTRec(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(MTRec, self).__init__()\n",
    "\n",
    "        self.W = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.q = nn.Parameter(torch.randn(hidden_dim))\n",
    "\n",
    "    def forward(self, history, candidates):\n",
    "        '''\n",
    "            B - batch size (keep in mind we use an unusual mini-batch approach)\n",
    "            H - history size (number of articles in the history, usually 30)\n",
    "            D - hidden size (768)\n",
    "            history:    B x H x D \n",
    "            candidates: B x 1 x D\n",
    "        '''\n",
    "\n",
    "        # print(f\"{candidates.shape=}\")\n",
    "        att = self.q * F.tanh(self.W(history))\n",
    "        att_weight = F.softmax(att, dim=1)\n",
    "        # print(f\"{att_weight.shape=}\")\n",
    "\n",
    "        user_embedding = torch.sum(history * att_weight, dim=1)\n",
    "        # print(f\"{user_embedding.shape=}\")\n",
    "        # print(f\"{user_embedding.unsqueeze(-1).shape=}\")\n",
    "        score = torch.bmm(candidates, user_embedding.unsqueeze(-1)) # B x M x 1\n",
    "        # print(score.shape)\n",
    "        return score.squeeze(-1)\n",
    "\n",
    "    def reshape(self, batch_news, bz):\n",
    "        n_news = len(batch_news) // bz\n",
    "        reshaped_batch = batch_news.reshape(bz, n_news, -1)\n",
    "        return reshaped_batch\n",
    "    \n",
    "model = MTRec(hidden_dim=768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 772:  Loss: 292.7912\r"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Assuming model and dataset are already defined\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "dataloader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "num_epochs = 5\n",
    "writer = SummaryWriter('runs/experiment_1')  # Specify your log directory\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    num_batches = len(dataloader)\n",
    "    losses = []\n",
    "    with tqdm(total=num_batches, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit='batch') as pbar:\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            history, candidates, labels = batch\n",
    "            history.squeeze_(0)\n",
    "            candidates.squeeze_(0)\n",
    "            labels.squeeze_(0)\n",
    "            labels = labels.to(torch.bool)\n",
    "\n",
    "            out = model(history, candidates)\n",
    "            # out[labels==0] = 0\n",
    "\n",
    "            # loss = nn.Gaussian(out, labels)\n",
    "            # loss = positive_nll(out, labels)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            pos = labels * out.exp()\n",
    "            neg = torch.sum((~labels) * out.exp(), dim=0)\n",
    "            # print(pos, neg)\n",
    "            loss = -torch.log(pos.sum(1) / (pos.sum(1) + neg + 1e-6)).sum()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            pbar.set_postfix({\"loss\": round(losses[-1], 3)})\n",
    "            pbar.update(1)\n",
    "            break\n",
    "    print(\"Average loss:\", np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#             out = model(history, candidates)\n",
    "#             loss = criterion(out, labels)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             running_loss += loss.item()\n",
    "            \n",
    "#             # Log the current loss value to TensorBoard\n",
    "#             writer.add_scalar('Loss/Train', loss.item(), epoch * num_batches + i)\n",
    "            \n",
    "#             # Update the progress bar\n",
    "#             pbar.set_postfix(loss=loss.item())\n",
    "#             pbar.update(1)\n",
    "    \n",
    "#     avg_loss = running_loss / num_batches\n",
    "#     epoch_time = time.time() - epoch_start_time\n",
    "    \n",
    "#     # Log the average loss and epoch time to TensorBoard\n",
    "#     writer.add_scalar('Loss/Avg_Train', avg_loss, epoch)\n",
    "#     writer.add_scalar('Time/Epoch', epoch_time, epoch)\n",
    "    \n",
    "#     # Display summary for the epoch\n",
    "#     print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "#     print(f\"Average loss: {avg_loss:.12f}\")\n",
    "#     print(f\"Epoch time: {epoch_time // 60:.0f}:{epoch_time % 60:02.0f}\\n\")\n",
    "\n",
    "# writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Click Predictor\n",
    "For each candidate news, we obtain its interest score $s_j$ by matching the candidate news vector $r^c_j$ and the user representation $r^u$ via dot product: $s_j = r^c_j · r^u$. \n",
    "\n",
    "### Loss Function\n",
    "Following previous work (Huang et al., 2013; Wu et al., 2019d), we employ the NCE loss to train the main ranking model. Then the main task loss LM ain is the negative log-likelihood of all positive samples in the training dataset D: \n",
    "\n",
    "$$ \\mathcal{L}_{Main} = − \\sum^{|D|}_{i=1} \\log{\\exp(s^+_i ) \\over \\exp(s^+_i ) + \\sum^L_{j=1} \\exp(s^j_i )} $$ \n",
    "\n",
    "where $s^+$ denotes the interest scores of positive news, $L$ indicates the number of negative news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
