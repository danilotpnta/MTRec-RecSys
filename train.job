#!/bin/bash

#SBATCH --partition=gpu
# Apparently we are now charged for 2 GPUs automatically, so might as well. Change this to 1 if model training errors arise.
#SBATCH --gpus=1
#SBATCH --gpus-per-node=1
#SBATCH --job-name=RECSYS
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=12
#SBATCH --time=00:09:00
#SBATCH --mem=64GB
#SBATCH --output=/home/scur0998/MTRec-RecSys/%A.out

date


WORK_DIR=$HOME/MTRec-RecSys
cd $WORK_DIR

module load 2023
module load Python/3.11.3-GCCcore-12.3.0
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
source $WORK_DIR/env/bin/activate

pip install -e .
pip install pytorch_lightning
pip install tensorboard 

export HF_DATASETS_CACHE=/scratch-local/scur0998/
export HF_DATASETS_IN_MEMORY_MAX_SIZE=118719476736 # 120GB
rm -rf $HF_DATASETS_CACHE/demo
python -m src.recsys.train \
    --data $HF_DATASETS_CACHE \
    --dataset demo --epochs 30 --bs 16 --lr 2e-5
