#!/bin/bash

#SBATCH --partition=gpu
# Apparently we are now charged for 2 GPUs automatically, so might as well. Change this to 1 if model training errors arise.
#SBATCH --gpus=1
#SBATCH --gpus-per-node=1
#SBATCH --job-name=RECSYS
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=12
#SBATCH --time=00:59:00
#SBATCH --mem=64GB
#SBATCH --output=/home/scur1595/MTRec-RecSys/%A.out

date


WORK_DIR=$HOME/MTRec-RecSys
cd $WORK_DIR

module load 2023
module load Python/3.11.3-GCCcore-12.3.0
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
source .venv/bin/activate

pip install -e .
pip install pytorch_lightning
pip install tensorboard 


export HF_DATASETS_IN_MEMORY_MAX_SIZE=118719476736 # 120GB
export HF_DATASETS_CACHE=/scratch-local/$(whoami)
rm -rf $HF_DATASETS_CACHE/demo
python -m src.recsys.train \
    --data $HF_DATASETS_CACHE \
    # --dataset demo --epochs 1 --bs 512 --lr 2e-5 --use_precomputed_embedding
