#!/bin/bash

#SBATCH --partition=gpu_mig
# Apparently we are now charged for 2 GPUs automatically, so might as well. Change this to 1 if model training errors arise.
#SBATCH --gpus=1
#SBATCH --gpus-per-node=1
#SBATCH --job-name=RECSYS
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=00:59:00
#SBATCH --mem=60GB
#SBATCH --output=/scratch-shared/recsys/%A.out

date


WORK_DIR=$HOME/MTRec-RecSys
cd $WORK_DIR

module load 2023
module load Python/3.11.3-GCCcore-12.3.0
module load PyTorch/2.1.2-foss-2023a-CUDA-12.1.1
source .venv/bin/activate

# pip install -e .
# pip install pytorch_lightning
# pip install tensorboard 

export HF_DATASETS_IN_MEMORY_MAX_SIZE=118719476736 # 120GB
export HF_DATASETS_CACHE=/scratch-local/$(whoami)
python -m src.recsys.train \
    --data $HF_DATASETS_CACHE \
    --dataset small --epochs 2 --bs 32 --lr 2e-5 --use_lora --precision bf16 --load_from_checkpoint /home/scur1595/MTRec-RecSys/checkpoints/epoch=09-step=142000.ckpt
    # --dataset demo --epochs 1 --bs 512 --lr 2e-5 --use_precomputed_embedding
